# ğŸ” Deep Dive into Apache Spark Source Code

Welcome to my personal deep-dive into the [Apache Spark](https://github.com/apache/spark) source code. This project is a curated, structured study of Sparkâ€™s internals â€” designed to help others understand its architecture, key components, and internal execution flow.

Each module is explored with detailed Markdown notes, code tracing, diagrams, and summaries.

---

## ğŸ“ Project Structure
spark-source-reading/
â”‚
â”œâ”€â”€ README.md                      # Overview (this file)
â”œâ”€â”€ core/                          # Core Spark internals (RDDs, context, scheduler)
â”‚   â”œâ”€â”€ RDD.md
â”‚   â”œâ”€â”€ SparkContext.md
â”‚   â”œâ”€â”€ DAGScheduler.md
â”‚   â””â”€â”€ TaskScheduler.md
â”‚
â”œâ”€â”€ sql/                           # SQL engine internals (Catalyst, Tungsten)
â”‚   â”œâ”€â”€ Catalyst.md
â”‚   â”œâ”€â”€ LogicalPlans.md
â”‚   â”œâ”€â”€ Optimizer.md
â”‚   â””â”€â”€ Tungsten.md
â”‚
â”œâ”€â”€ streaming/                     # Spark Streaming concepts and internals
â”‚   â””â”€â”€ Overview.md
â”‚
â”œâ”€â”€ diagrams/                      # Visuals and architecture diagrams
â”‚   â””â”€â”€ spark-architecture.png
â”‚
â””â”€â”€ examples/                      # Explanations of sample Spark applications
    â””â”€â”€ sparkpi-explained.md
---

## ğŸ“Œ Goals

- Understand how Apache Spark works under the hood
- Summarize key components like RDD, DAG scheduler, Catalyst optimizer
- Provide annotated diagrams and call flows
- Make it easier for new contributors to onboard into Spark

---

## ğŸ§  Topics Covered

### ğŸ”§ Core Components (`core/`)
| File | Summary |
|------|---------|
| `RDD.md` | Explains Spark's RDD abstraction, lazy evaluation, lineage, compute model |
| `SparkContext.md` | The entry point of any Spark application â€“ driver program interactions |
| `DAGScheduler.md` | Translates jobs into stage DAGs |
| `TaskScheduler.md` | Handles actual task scheduling and execution on executors |

---

### ğŸ§® SQL Engine (`sql/`)
| File | Summary |
|------|---------|
| `Catalyst.md` | Deep dive into the Catalyst query optimization framework |
| `LogicalPlans.md` | How logical query plans are constructed |
| `Optimizer.md` | How Catalyst applies optimization rules |
| `Tungsten.md` | Physical execution layer focused on memory + CPU efficiency |

---

### ğŸ” Streaming (`streaming/`)
| File | Summary |
|------|---------|
| `Overview.md` | Architecture of Spark Streaming, micro-batches, DStreams |

---

### ğŸ“Œ Examples (`examples/`)
| File | Summary |
|------|---------|
| `sparkpi-explained.md` | Breaks down the `SparkPi` example to understand execution flow |

---

## ğŸ§­ How to Use This Repository

If you're a:
- **Beginner** â†’ Start with `examples/sparkpi-explained.md`
- **Intermediate** â†’ Move to `core/RDD.md` and `core/SparkContext.md`
- **Advanced** â†’ Explore `sql/`, Catalyst, and internal optimizations

---

## ğŸ“Š Diagrams

Visual aids are in the `diagrams/` folder. For example:

![Spark Architecture](diagrams/spark-architecture.png)

---

## ğŸ”— References

- [Apache Spark GitHub](https://github.com/apache/spark)
- [Spark Architecture Overview](https://spark.apache.org/docs/latest/cluster-overview.html)
- [Spark SQL Guide](https://spark.apache.org/docs/latest/sql-getting-started.html)

---

## ğŸ™Œ Contributions

This is a personal learning project. Feel free to fork, star, or suggest improvements via issues or PRs.

---

## ğŸ“… Progress Tracker

| Module | Status |
|--------|--------|
| RDD.md | âœ… In Progress |
| SparkContext.md | â³ Planned |
| Catalyst.md | â³ Planned |
| ... | ... |

---

## ğŸ§‘â€ğŸ’» Author

Maintained by [Yasin Rezaei](https://github.com/yasinrezaei)

---


